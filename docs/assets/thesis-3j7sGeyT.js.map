{"version":3,"file":"thesis-3j7sGeyT.js","sources":["../../../pages/thesis.md"],"sourcesContent":["UDC 111.11\n\n**DEVELOPMENT OF AN APPLICATION FOR AUTOMATED EDUCATIONAL TASK GENERATION BASED ON TEXT USING NLP AND LIGHTWEIGHT LLMS**\n\n***Nosenko M.I., student; Kudin O.V., Docent***  \n***Zaporizhzhia National University***\n\nNatural Language Processing (NLP) has advanced significantly with the emergence of large language models (LLMs). Despite their popularity, classical NLP methods remain practical for certain educational tasks. The growing demand for energy-efficient solutions highlights the need for lightweight, hybrid approaches.\n\nRecent studies confirm the effectiveness of LLMs in generating educational content \\[1\\].  However, concerns remain about their energy consumption and scalability \\[2, 3\\]. Classical NLP techniques, such as rule-based processing and syntactic parsing, can still be competitive \\[4, 5\\].  Both LLM and classical approaches face challenges in multilingual environments \\[6, 7\\].\n\nThe application combines classical NLP methods (POS-tagging, NER, dependency parsing) with optional lightweight LLMs. We use Python-based tools such as FastAPI, NLTK, and transformer models via Hugging Face. UML diagrams were used during the planning phase to outline system logic and workflows.\n\nA prototype application was designed to generate tasks such as:\n\n1. Cloze (fill-in-the-blank) exercises.  \n2. Multiple-choice generation.\n\nInitial testing shows that basic tasks can be reliably handled using classical NLP, while lightweight LLMs improve fluency and coherence when applied locally.\n\nThe system demonstrates that full-scale LLMs are not always necessary for educational NLP applications. Compared to purely LLM-based platforms, this approach offers a more energy-efficient and accessible alternative. It is suitable for offline or resource-constrained environments such as schools and regional platforms.\n\nA hybrid system for educational task generation was developed using classical NLP and compact LLMs. It achieves a balance between resource efficiency and task quality. Future research will explore multilingual support and additional types of tasks.\n\n**LITERATURE**\n\n1. Ling J., Afzaal M. Automatic question-answer pairs generation using pre-trained large language models in higher education. *Computers and education: artificial intelligence*. 2024\\. Т. 6\\. С. 100252\\. DOI: [10.1016/j.caeai.2024.100252](https://doi.org/10.1016/j.caeai.2024.100252).\n\n2. D. Patterson et al. The carbon footprint of machine learning training will plateau, then shrink. *arXiv.org e-Print archive*. URL: [https://arxiv.org/pdf/2204.05149](https://arxiv.org/pdf/2204.05149) (date of access: 05.04.2025).\n\n3. Chen M. et al. Evaluating large language models trained on code. *arXiv.org e-Print archive*. URL: [https://arxiv.org/pdf/2107.03374](https://arxiv.org/pdf/2107.03374) (date of access: 05.04.2025).\n\n4. Kwon N., Yoo Y., Lee B. Class conditioned text generation with style attention mechanism for embracing diversity. *Applied soft computing*. 2024\\. С. 111893\\. DOI: [10.1016/j.asoc.2024.111893](https://doi.org/10.1016/j.asoc.2024.111893).\n\n5. O. Baclic et al. Challenges and opportunities for public health made possible by advances in natural language processing. *Canada communicable disease report*. 2020\\. С. 161–168. DOI: [10.14745/ccdr.v46i06a02](https://doi.org/10.14745/ccdr.v46i06a02).\n\n6. R. Choenni et al. On the evaluation practices in multilingual NLP: can machine translation offer an alternative to human translations? . *arXiv.org*. DOI: [10.48550/arXiv.2406.14267](https://doi.org/10.48550/arXiv.2406.14267).\n\n7. L. Qin et al. Large language models meet NLP: a survey. *arXiv.org*. DOI: [10.48550/arXiv.2405.12819](https://doi.org/10.48550/arXiv.2405.12819).\n\n"],"names":["_jsx","_components"],"mappings":"mPAAA,SAAA;sCAEE,SAAA;6DAEC,SAAA;uCACA,SAAA;aAEH,SAAA;aAEA,SAAA;aAEA,SAAA;aAEA,SAAA;;cAEG,SAAA;cACA,SAAA;;aAEH,SAAA;aAEA,SAAA;aAEA,SAAA;sCAEE,SAAA;;;cAEC,SAAA,CAAA,8HAAAA,MAAAC,EAAA,GAAA,CAA4H,SAAA,kDAAiD,CAAA,EAAA,iCAAAD,MAAAC,EAAA,EAAA,oDAAkC,SAAA,6BAAyE,CAAA,EAAA,GAAA;;;cAExR,SAAA,CAAA,oGAAAD,MAAAC,EAAA,GAAA,CAAkG,SAAA,2BAA0B,CAAA,EAAA,UAAAD,MAAAC,EAAA,EAAA,yCAAQ,SAAA,kCAAmE,CAAA,EAAA,gCAAA;;;cAEvM,SAAA,CAAA,oEAAAD,MAAAC,EAAA,GAAA,CAAkE,SAAA,2BAA0B,CAAA,EAAA,UAAAD,MAAAC,EAAA,EAAA,yCAAQ,SAAA,kCAAmE,CAAA,EAAA,gCAAA;;;cAEvK,SAAA,CAAA,qHAAAD,MAAAC,EAAA,GAAA,CAAmH,SAAA,wBAAuB,CAAA,EAAA,2BAAAD,MAAAC,EAAA,EAAA,mDAA2B,SAAA,4BAAuE,CAAA,EAAA,GAAA;;;cAE5O,SAAA,CAAA,6HAAAD,MAAAC,EAAA,GAAA,CAA2H,SAAA,oCAAmC,CAAA,EAAA,4BAAAD,MAAAC,EAAA,EAAA,gDAA2B,SAAA,yBAAiE,CAAA,EAAA,GAAA;;;cAE1P,SAAA,CAAA,4IAAAD,MAAAC,EAAA,GAAA,CAA0I,SAAA,WAAU,CAAA,EAAA,UAAAD,MAAAC,EAAA,EAAA,kDAAQ,SAAA,2BAAqE,CAAA,EAAA,GAAA;;;cAEjO,SAAA,CAAA,2DAAAD,MAAAC,EAAA,GAAA,CAAyD,SAAA,WAAU,CAAA,EAAA,UAAAD,MAAAC,EAAA,EAAA,kDAAQ,SAAA,2BAAqE,CAAA,EAAA,GAAA;;"}